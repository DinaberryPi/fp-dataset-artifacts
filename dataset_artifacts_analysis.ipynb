{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RMqfJifXdeT"
      },
      "source": [
        "# Analyzing and Mitigating Dataset Artifacts in NLI\n",
        "\n",
        "**Project:** Final Project - CS388  \n",
        "**Dataset:** SNLI (Stanford Natural Language Inference)  \n",
        "**Model:** ELECTRA-small  \n",
        "**Goal:** Detect and mitigate dataset artifacts using hypothesis-only baselines and ensemble debiasing\n",
        "\n",
        "## Project Structure\n",
        "- **Part 1: Analysis** - Detect artifacts and analyze model errors\n",
        "- **Part 2: Fix** - Implement and evaluate debiasing method\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_lcimFkXdeX"
      },
      "source": [
        "## Setup and Installation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKOZBDxTXdea",
        "outputId": "2f24b52f-7e1e-49dc-fcf6-fd45f04de6a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'fp-dataset-artifacts'...\n",
            "remote: Enumerating objects: 139, done.\u001b[K\n",
            "remote: Counting objects: 100% (21/21), done.\u001b[K\n",
            "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
            "remote: Total 139 (delta 15), reused 10 (delta 10), pack-reused 118 (from 3)\u001b[K\n",
            "Receiving objects: 100% (139/139), 8.13 MiB | 15.68 MiB/s, done.\n",
            "Resolving deltas: 100% (55/55), done.\n"
          ]
        }
      ],
      "source": [
        "# Connecting using personal token\n",
        "\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ['gituser'] = userdata.get('gituser')\n",
        "os.environ['gitpw'] = userdata.get('gitpw')\n",
        "os.environ['REPO'] = 'fp-dataset-artifacts'\n",
        "\n",
        "!git clone https://$gituser:$gitpw@github.com/$gituser/$REPO.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vR8C5MLoND1t",
        "outputId": "6412fc0a-466d-4d9d-e463-de7f79246b89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/fp-dataset-artifacts\n"
          ]
        }
      ],
      "source": [
        "%cd fp-dataset-artifacts/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oolh9J2zXdeX",
        "outputId": "9a6712e4-f340-415d-a9e6-57a31a8f163a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/84.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "%pip install -q -r requirements.txt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwehh7rBXdeb"
      },
      "source": [
        "## Part 1: Analysis\n",
        "\n",
        "### Part 1.1: Baseline Model Training\n",
        "\n",
        "Train a standard NLI model on SNLI dataset using both premise and hypothesis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54jEB8HONL0B",
        "outputId": "c49a1e66-765a-477b-8af4-d87e8613e1df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-11-18 19:19:43.875385: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1763493583.896605   15703 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1763493583.903012   15703 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1763493583.920181   15703 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763493583.920208   15703 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763493583.920211   15703 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763493583.920213   15703 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-11-18 19:19:43.925197: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "README.md: 16.0kB [00:00, 52.7MB/s]\n",
            "plain_text/test-00000-of-00001.parquet: 100% 412k/412k [00:01<00:00, 281kB/s]\n",
            "plain_text/validation-00000-of-00001.par(…): 100% 413k/413k [00:00<00:00, 801kB/s]\n",
            "plain_text/train-00000-of-00001.parquet: 100% 19.6M/19.6M [00:00<00:00, 27.0MB/s]\n",
            "Generating test split: 100% 10000/10000 [00:00<00:00, 271309.16 examples/s]\n",
            "Generating validation split: 100% 10000/10000 [00:00<00:00, 1552353.53 examples/s]\n",
            "Generating train split: 100% 550152/550152 [00:00<00:00, 2816853.89 examples/s]\n",
            "config.json: 100% 665/665 [00:00<00:00, 7.04MB/s]\n",
            "pytorch_model.bin: 100% 54.2M/54.2M [00:00<00:00, 57.3MB/s]\n",
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "tokenizer_config.json: 100% 48.0/48.0 [00:00<00:00, 320kB/s]\n",
            "vocab.txt: 232kB [00:00, 67.5MB/s]\n",
            "tokenizer.json: 466kB [00:00, 137MB/s]\n",
            "model.safetensors:   0% 0.00/54.2M [00:00<?, ?B/s]Preprocessing data... (this takes a little bit, should only happen once per dataset)\n",
            "\n",
            "Filter: 100% 10000/10000 [00:00<00:00, 245486.23 examples/s]\n",
            "\n",
            "Filter: 100% 10000/10000 [00:00<00:00, 262419.54 examples/s]\n",
            "\n",
            "Filter:   0% 0/550152 [00:00<?, ? examples/s]\u001b[A\n",
            "Filter:   5% 28000/550152 [00:00<00:01, 267317.31 examples/s]\u001b[A\n",
            "Filter:  10% 56000/550152 [00:00<00:01, 269358.61 examples/s]\u001b[A\n",
            "model.safetensors: 100% 54.2M/54.2M [00:00<00:00, 84.2MB/s]\n",
            "\n",
            "Filter:  22% 123000/550152 [00:00<00:01, 259519.33 examples/s]\u001b[A\n",
            "Filter:  27% 151000/550152 [00:00<00:01, 261944.09 examples/s]\u001b[A\n",
            "Filter:  33% 179000/550152 [00:00<00:01, 265880.97 examples/s]\u001b[A\n",
            "Filter:  38% 207000/550152 [00:00<00:01, 267203.21 examples/s]\u001b[A\n",
            "Filter:  43% 235000/550152 [00:00<00:01, 267622.47 examples/s]\u001b[A\n",
            "Filter:  48% 263000/550152 [00:00<00:01, 270737.99 examples/s]\u001b[A\n",
            "Filter:  53% 291000/550152 [00:01<00:00, 270476.22 examples/s]\u001b[A\n",
            "Filter:  58% 319000/550152 [00:01<00:00, 272560.45 examples/s]\u001b[A\n",
            "Filter:  63% 347000/550152 [00:01<00:00, 270995.13 examples/s]\u001b[A\n",
            "Filter:  68% 375000/550152 [00:01<00:00, 271127.82 examples/s]\u001b[A\n",
            "Filter:  73% 403000/550152 [00:01<00:00, 271400.83 examples/s]\u001b[A\n",
            "Filter:  78% 431000/550152 [00:01<00:00, 271095.03 examples/s]\u001b[A\n",
            "Filter:  83% 459000/550152 [00:01<00:00, 271444.29 examples/s]\u001b[A\n",
            "Filter:  89% 487000/550152 [00:01<00:00, 270112.67 examples/s]\u001b[A\n",
            "Filter:  94% 515000/550152 [00:01<00:00, 270197.28 examples/s]\u001b[A\n",
            "Filter: 100% 550152/550152 [00:02<00:00, 268345.02 examples/s]\n",
            "Map (num_proc=2): 100% 100000/100000 [00:10<00:00, 9873.97 examples/s]\n",
            "Map (num_proc=2): 100% 9842/9842 [00:01<00:00, 8418.34 examples/s]\n",
            "/content/fp-dataset-artifacts/train/run.py:163: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = trainer_class(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose \"Don't visualize my results\"\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.22.3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory. Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/fp-dataset-artifacts/wandb/offline-run-20251118_193302-jrbbpz27\u001b[0m\n",
            "{'loss': 0.8981, 'grad_norm': 6.298059940338135, 'learning_rate': 1.893546666666667e-05, 'epoch': 0.16}\n",
            "{'loss': 0.6551, 'grad_norm': 5.120357036590576, 'learning_rate': 1.78688e-05, 'epoch': 0.32}\n",
            "{'loss': 0.5803, 'grad_norm': 11.196693420410156, 'learning_rate': 1.6802133333333336e-05, 'epoch': 0.48}\n",
            "{'loss': 0.5602, 'grad_norm': 8.08327579498291, 'learning_rate': 1.573546666666667e-05, 'epoch': 0.64}\n",
            "{'loss': 0.5373, 'grad_norm': 9.112153053283691, 'learning_rate': 1.4668800000000001e-05, 'epoch': 0.8}\n",
            "{'loss': 0.522, 'grad_norm': 10.559992790222168, 'learning_rate': 1.3602133333333333e-05, 'epoch': 0.96}\n",
            "{'loss': 0.4858, 'grad_norm': 11.410141944885254, 'learning_rate': 1.2535466666666667e-05, 'epoch': 1.12}\n",
            "{'loss': 0.4687, 'grad_norm': 10.33659839630127, 'learning_rate': 1.14688e-05, 'epoch': 1.28}\n",
            "{'loss': 0.4676, 'grad_norm': 5.996679306030273, 'learning_rate': 1.0402133333333335e-05, 'epoch': 1.44}\n",
            "{'loss': 0.4569, 'grad_norm': 6.6321330070495605, 'learning_rate': 9.335466666666667e-06, 'epoch': 1.6}\n",
            "{'loss': 0.4613, 'grad_norm': 6.240365028381348, 'learning_rate': 8.2688e-06, 'epoch': 1.76}\n",
            "{'loss': 0.4521, 'grad_norm': 7.287844181060791, 'learning_rate': 7.202133333333334e-06, 'epoch': 1.92}\n",
            "{'loss': 0.4264, 'grad_norm': 10.291447639465332, 'learning_rate': 6.135466666666667e-06, 'epoch': 2.08}\n",
            "{'loss': 0.4172, 'grad_norm': 8.106945037841797, 'learning_rate': 5.0688000000000005e-06, 'epoch': 2.24}\n",
            "{'loss': 0.4203, 'grad_norm': 8.027350425720215, 'learning_rate': 4.002133333333334e-06, 'epoch': 2.4}\n",
            "{'loss': 0.4137, 'grad_norm': 9.744311332702637, 'learning_rate': 2.935466666666667e-06, 'epoch': 2.56}\n",
            "{'loss': 0.4132, 'grad_norm': 7.578009605407715, 'learning_rate': 1.8688e-06, 'epoch': 2.72}\n",
            "{'loss': 0.4154, 'grad_norm': 9.315777778625488, 'learning_rate': 8.021333333333334e-07, 'epoch': 2.88}\n",
            "{'train_runtime': 1758.7161, 'train_samples_per_second': 170.579, 'train_steps_per_second': 5.331, 'train_loss': 0.49886423014322917, 'epoch': 3.0}\n",
            "100% 9375/9375 [16:50<00:00,  9.27it/s]\n",
            "100% 308/308 [00:12<00:00, 24.27it/s]\n",
            "Evaluation results:\n",
            "{'eval_loss': 0.4014982581138611, 'eval_accuracy': 0.8511481285095215, 'eval_runtime': 12.7376, 'eval_samples_per_second': 772.671, 'eval_steps_per_second': 24.18, 'epoch': 3.0}\n",
            "\u001b[1;34mwandb\u001b[0m: \n",
            "\u001b[1;34mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
            "\u001b[1;34mwandb\u001b[0m: \u001b[1mwandb sync /content/fp-dataset-artifacts/wandb/offline-run-20251118_193302-jrbbpz27\u001b[0m\n",
            "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/offline-run-20251118_193302-jrbbpz27/logs\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python train/run.py --do_train --do_eval --task nli --dataset snli --model google/electra-small-discriminator --output_dir ./outputs/evaluations/baseline_100k/ --max_train_samples 100000 --num_train_epochs 3 --per_device_train_batch_size 32 --per_device_eval_batch_size 32 --max_length 128 --learning_rate 2e-5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1JksB0NXdec",
        "outputId": "915ee33c-847e-42d1-f6c0-09f8a71af898"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "Baseline Model Results\n",
            "================================================================================\n",
            "Accuracy: 0.8654 (86.54%)\n",
            "Eval Loss: 0.3831678628921509\n"
          ]
        }
      ],
      "source": [
        "# Check baseline results\n",
        "import json\n",
        "with open(os.path.join('outputs', 'evaluations', 'baseline_100k', 'eval_metrics.json'), 'r') as f:\n",
        "    baseline_metrics = json.load(f)\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"Baseline Model Results\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"Accuracy: {baseline_metrics['eval_accuracy']:.4f} ({baseline_metrics['eval_accuracy']*100:.2f}%)\")\n",
        "print(f\"Eval Loss: {baseline_metrics.get('eval_loss', 'N/A')}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3s0gHCgWXded"
      },
      "source": [
        "### Part 1.2: Artifact Detection - Hypothesis-Only Model\n",
        "\n",
        "Train a model that only sees the hypothesis (not the premise) to detect dataset artifacts.  \n",
        "If this model achieves >33.33% accuracy (random baseline), it indicates strong artifacts exist.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MAiKmrDXded",
        "outputId": "5485d07a-b83f-4505-d03c-a78f40d9618d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-11-19 04:00:09.090136: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1763524809.115943    3359 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1763524809.123488    3359 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1763524809.144010    3359 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763524809.144058    3359 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763524809.144063    3359 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763524809.144067    3359 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-11-19 04:00:09.150007: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "================================================================================\n",
            "TRAINING HYPOTHESIS-ONLY MODEL (Artifact Model)\n",
            "This model only sees the hypothesis, not the premise!\n",
            "It will learn to exploit dataset artifacts.\n",
            "================================================================================\n",
            "\n",
            "Loading SNLI dataset...\n",
            "README.md: 16.0kB [00:00, 33.9MB/s]\n",
            "plain_text/test-00000-of-00001.parquet: 100% 412k/412k [00:00<00:00, 755kB/s]\n",
            "plain_text/validation-00000-of-00001.par(…): 100% 413k/413k [00:00<00:00, 3.74MB/s]\n",
            "plain_text/train-00000-of-00001.parquet: 100% 19.6M/19.6M [00:00<00:00, 47.6MB/s]\n",
            "Generating test split: 100% 10000/10000 [00:00<00:00, 189368.50 examples/s]\n",
            "Generating validation split: 100% 10000/10000 [00:00<00:00, 811701.28 examples/s]\n",
            "Generating train split: 100% 550152/550152 [00:00<00:00, 1286483.36 examples/s]\n",
            "Filter: 100% 10000/10000 [00:00<00:00, 188726.03 examples/s]\n",
            "Filter: 100% 10000/10000 [00:00<00:00, 196454.52 examples/s]\n",
            "Filter: 100% 550152/550152 [00:03<00:00, 168665.85 examples/s]\n",
            "\n",
            "Loading model: google/electra-small-discriminator\n",
            "config.json: 100% 665/665 [00:00<00:00, 3.76MB/s]\n",
            "pytorch_model.bin: 100% 54.2M/54.2M [00:00<00:00, 55.6MB/s]\n",
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "tokenizer_config.json: 100% 48.0/48.0 [00:00<00:00, 314kB/s]\n",
            "vocab.txt: 232kB [00:00, 10.6MB/s]\n",
            "tokenizer.json: 466kB [00:00, 28.2MB/s]\n",
            "model.safetensors:   0% 0.00/54.2M [00:00<?, ?B/s]\n",
            "Preparing datasets (hypothesis-only)...\n",
            "\n",
            "Map (num_proc=2):   0% 0/100000 [00:00<?, ? examples/s]\u001b[A\n",
            "model.safetensors: 100% 54.2M/54.2M [00:00<00:00, 62.4MB/s]\n",
            "\n",
            "Map (num_proc=2):   2% 2000/100000 [00:00<00:37, 2635.50 examples/s]\u001b[A\n",
            "Map (num_proc=2):   3% 3000/100000 [00:01<00:29, 3280.62 examples/s]\u001b[A\n",
            "Map (num_proc=2):   5% 5000/100000 [00:01<00:20, 4609.66 examples/s]\u001b[A\n",
            "Map (num_proc=2):   7% 7000/100000 [00:01<00:16, 5645.75 examples/s]\u001b[A\n",
            "Map (num_proc=2):   9% 9000/100000 [00:01<00:14, 6125.62 examples/s]\u001b[A\n",
            "Map (num_proc=2):  11% 11000/100000 [00:02<00:13, 6628.46 examples/s]\u001b[A\n",
            "Map (num_proc=2):  13% 13000/100000 [00:02<00:12, 6935.66 examples/s]\u001b[A\n",
            "Map (num_proc=2):  15% 15000/100000 [00:02<00:11, 7108.31 examples/s]\u001b[A\n",
            "Map (num_proc=2):  17% 17000/100000 [00:02<00:11, 7185.78 examples/s]\u001b[A\n",
            "Map (num_proc=2):  19% 19000/100000 [00:03<00:11, 7319.86 examples/s]\u001b[A\n",
            "Map (num_proc=2):  21% 21000/100000 [00:03<00:10, 7434.75 examples/s]\u001b[A\n",
            "Map (num_proc=2):  23% 23000/100000 [00:03<00:10, 7561.69 examples/s]\u001b[A\n",
            "Map (num_proc=2):  25% 25000/100000 [00:04<00:10, 7406.11 examples/s]\u001b[A\n",
            "Map (num_proc=2):  27% 27000/100000 [00:04<00:09, 7396.74 examples/s]\u001b[A\n",
            "Map (num_proc=2):  29% 29000/100000 [00:04<00:09, 7551.62 examples/s]\u001b[A\n",
            "Map (num_proc=2):  31% 31000/100000 [00:04<00:09, 7637.30 examples/s]\u001b[A\n",
            "Map (num_proc=2):  33% 33000/100000 [00:05<00:08, 7573.20 examples/s]\u001b[A\n",
            "Map (num_proc=2):  35% 35000/100000 [00:05<00:08, 7739.30 examples/s]\u001b[A\n",
            "Map (num_proc=2):  37% 37000/100000 [00:05<00:08, 7753.76 examples/s]\u001b[A\n",
            "Map (num_proc=2):  39% 39000/100000 [00:05<00:07, 7769.67 examples/s]\u001b[A\n",
            "Map (num_proc=2):  41% 41000/100000 [00:06<00:07, 7602.75 examples/s]\u001b[A\n",
            "Map (num_proc=2):  43% 43000/100000 [00:06<00:07, 7622.84 examples/s]\u001b[A\n",
            "Map (num_proc=2):  45% 45000/100000 [00:06<00:07, 7596.53 examples/s]\u001b[A\n",
            "Map (num_proc=2):  47% 47000/100000 [00:06<00:06, 7694.60 examples/s]\u001b[A\n",
            "Map (num_proc=2):  49% 49000/100000 [00:07<00:06, 7625.08 examples/s]\u001b[A\n",
            "Map (num_proc=2):  51% 51000/100000 [00:07<00:06, 7428.08 examples/s]\u001b[A\n",
            "Map (num_proc=2):  53% 53000/100000 [00:07<00:06, 7603.82 examples/s]\u001b[A\n",
            "Map (num_proc=2):  55% 55000/100000 [00:07<00:05, 7641.15 examples/s]\u001b[A\n",
            "Map (num_proc=2):  57% 57000/100000 [00:08<00:05, 7641.44 examples/s]\u001b[A\n",
            "Map (num_proc=2):  59% 59000/100000 [00:08<00:05, 7488.66 examples/s]\u001b[A\n",
            "Map (num_proc=2):  61% 61000/100000 [00:08<00:05, 7570.76 examples/s]\u001b[A\n",
            "Map (num_proc=2):  63% 63000/100000 [00:09<00:05, 7145.29 examples/s]\u001b[A\n",
            "Map (num_proc=2):  65% 65000/100000 [00:09<00:05, 6779.80 examples/s]\u001b[A\n",
            "Map (num_proc=2):  66% 66000/100000 [00:09<00:05, 5857.78 examples/s]\u001b[A\n",
            "Map (num_proc=2):  67% 67000/100000 [00:09<00:05, 6121.21 examples/s]\u001b[A\n",
            "Map (num_proc=2):  68% 68000/100000 [00:10<00:06, 4756.39 examples/s]\u001b[A\n",
            "Map (num_proc=2):  69% 69000/100000 [00:10<00:06, 4988.11 examples/s]\u001b[A\n",
            "Map (num_proc=2):  70% 70000/100000 [00:10<00:06, 4454.45 examples/s]\u001b[A\n",
            "Map (num_proc=2):  71% 71000/100000 [00:10<00:05, 5007.21 examples/s]\u001b[A\n",
            "Map (num_proc=2):  72% 72000/100000 [00:11<00:06, 4273.56 examples/s]\u001b[A\n",
            "Map (num_proc=2):  74% 74000/100000 [00:11<00:05, 5000.44 examples/s]\u001b[A\n",
            "Map (num_proc=2):  75% 75000/100000 [00:11<00:04, 5009.35 examples/s]\u001b[A\n",
            "Map (num_proc=2):  76% 76000/100000 [00:11<00:04, 5287.96 examples/s]\u001b[A\n",
            "Map (num_proc=2):  77% 77000/100000 [00:11<00:04, 4955.34 examples/s]\u001b[A\n",
            "Map (num_proc=2):  78% 78000/100000 [00:12<00:04, 4814.41 examples/s]\u001b[A\n",
            "Map (num_proc=2):  79% 79000/100000 [00:12<00:04, 5215.46 examples/s]\u001b[A\n",
            "Map (num_proc=2):  80% 80000/100000 [00:12<00:04, 4676.10 examples/s]\u001b[A\n",
            "Map (num_proc=2):  81% 81000/100000 [00:14<00:13, 1439.83 examples/s]\u001b[A\n",
            "Map (num_proc=2):  82% 82000/100000 [00:14<00:10, 1755.54 examples/s]\u001b[A\n",
            "Map (num_proc=2):  83% 83000/100000 [00:14<00:07, 2301.59 examples/s]\u001b[A\n",
            "Map (num_proc=2):  84% 84000/100000 [00:15<00:05, 2812.36 examples/s]\u001b[A\n",
            "Map (num_proc=2):  85% 85000/100000 [00:15<00:04, 3352.29 examples/s]\u001b[A\n",
            "Map (num_proc=2):  86% 86000/100000 [00:15<00:03, 4145.51 examples/s]\u001b[A\n",
            "Map (num_proc=2):  87% 87000/100000 [00:15<00:03, 4320.34 examples/s]\u001b[A\n",
            "Map (num_proc=2):  88% 88000/100000 [00:15<00:02, 4990.05 examples/s]\u001b[A\n",
            "Map (num_proc=2):  89% 89000/100000 [00:15<00:01, 5518.77 examples/s]\u001b[A\n",
            "Map (num_proc=2):  90% 90000/100000 [00:15<00:01, 5446.24 examples/s]\u001b[A\n",
            "Map (num_proc=2):  91% 91000/100000 [00:16<00:01, 6040.60 examples/s]\u001b[A\n",
            "Map (num_proc=2):  92% 92000/100000 [00:16<00:01, 5058.16 examples/s]\u001b[A\n",
            "Map (num_proc=2):  94% 94000/100000 [00:16<00:01, 5872.62 examples/s]\u001b[A\n",
            "Map (num_proc=2):  96% 96000/100000 [00:16<00:00, 6548.88 examples/s]\u001b[A\n",
            "Map (num_proc=2):  97% 97000/100000 [00:17<00:00, 5773.73 examples/s]\u001b[A\n",
            "Map (num_proc=2): 100% 100000/100000 [00:17<00:00, 5608.82 examples/s]\n",
            "Map (num_proc=2): 100% 9842/9842 [00:02<00:00, 3507.99 examples/s]\n",
            "/content/fp-dataset-artifacts/train/train_hypothesis_only.py:93: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "\n",
            "================================================================================\n",
            "STARTING TRAINING...\n",
            "Remember: This model CANNOT see the premise!\n",
            "High accuracy = strong artifacts in the dataset\n",
            "================================================================================\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose \"Don't visualize my results\"\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.22.3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory. Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/fp-dataset-artifacts/wandb/offline-run-20251119_040316-l2xe8dfd\u001b[0m\n",
            "  0% 0/18750 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "{'loss': 1.0919, 'grad_norm': 1.848745346069336, 'learning_rate': 4.9736000000000006e-05, 'epoch': 0.02}\n",
            "{'loss': 1.0358, 'grad_norm': 3.0875296592712402, 'learning_rate': 4.946933333333333e-05, 'epoch': 0.03}\n",
            "{'loss': 0.9972, 'grad_norm': 4.023515224456787, 'learning_rate': 4.920266666666667e-05, 'epoch': 0.05}\n",
            "{'loss': 0.9634, 'grad_norm': 4.2560882568359375, 'learning_rate': 4.893600000000001e-05, 'epoch': 0.06}\n",
            "{'loss': 0.9334, 'grad_norm': 3.9869766235351562, 'learning_rate': 4.866933333333333e-05, 'epoch': 0.08}\n",
            "  3% 568/18750 [32:34<16:58:32,  3.36s/it]Traceback (most recent call last):\n",
            "  File \"/content/fp-dataset-artifacts/train/train_hypothesis_only.py\", line 154, in <module>\n",
            "    main()\n",
            "  File \"/content/fp-dataset-artifacts/train/train_hypothesis_only.py\", line 109, in main\n",
            "    trainer.train()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\", line 2325, in train\n",
            "    return inner_training_loop(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\", line 2674, in _inner_training_loop\n",
            "    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\", line 4020, in training_step\n",
            "    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\", line 4110, in compute_loss\n",
            "    outputs = model(**inputs)\n",
            "              ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/models/electra/modeling_electra.py\", line 967, in forward\n",
            "    discriminator_hidden_states = self.electra(\n",
            "                                  ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/models/electra/modeling_electra.py\", line 789, in forward\n",
            "    hidden_states = self.encoder(\n",
            "                    ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/models/electra/modeling_electra.py\", line 559, in forward\n",
            "    layer_outputs = layer_module(\n",
            "                    ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/modeling_layers.py\", line 94, in __call__\n",
            "    return super().__call__(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/utils/deprecation.py\", line 172, in wrapped_func\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/models/electra/modeling_electra.py\", line 466, in forward\n",
            "    self_attention_outputs = self.attention(\n",
            "                             ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/utils/deprecation.py\", line 172, in wrapped_func\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/models/electra/modeling_electra.py\", line 393, in forward\n",
            "    self_outputs = self.self(\n",
            "                   ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/utils/deprecation.py\", line 172, in wrapped_func\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/models/electra/modeling_electra.py\", line 283, in forward\n",
            "    attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "\u001b[1;34mwandb\u001b[0m: \n",
            "\u001b[1;34mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
            "\u001b[1;34mwandb\u001b[0m: \u001b[1mwandb sync /content/fp-dataset-artifacts/wandb/offline-run-20251119_040316-l2xe8dfd\u001b[0m\n",
            "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/offline-run-20251119_040316-l2xe8dfd/logs\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python train/train_hypothesis_only.py\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOTyvYoFXded",
        "outputId": "a0ded135-73b5-42c1-f557-857f5e0dc72e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "Hypothesis-Only Model Results (Artifact Detection)\n",
            "================================================================================\n",
            "Accuracy: 0.6080 (60.80%)\n",
            "Random Baseline: 0.3333 (33.33%)\n",
            "Above Random: 0.2747 (27.47%)\n",
            "\n",
            "STRONG ARTIFACTS DETECTED!\n"
          ]
        }
      ],
      "source": [
        "# Check hypothesis-only results\n",
        "with open(os.path.join('outputs', 'evaluations', 'hypothesis_only_model', 'eval_metrics.json'), 'r') as f:\n",
        "    hyp_metrics = json.load(f)\n",
        "\n",
        "hyp_accuracy = hyp_metrics['eval_accuracy']\n",
        "random_baseline = 1.0 / 3.0\n",
        "above_random = hyp_accuracy - random_baseline\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"Hypothesis-Only Model Results (Artifact Detection)\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"Accuracy: {hyp_accuracy:.4f} ({hyp_accuracy*100:.2f}%)\")\n",
        "print(f\"Random Baseline: {random_baseline:.4f} ({random_baseline*100:.2f}%)\")\n",
        "print(f\"Above Random: {above_random:.4f} ({above_random*100:.2f}%)\")\n",
        "print(f\"\\n{'STRONG ARTIFACTS DETECTED!' if above_random > 0.2 else 'Weak artifacts detected' if above_random > 0.1 else 'No significant artifacts'}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEJDI0HAXdee"
      },
      "source": [
        "### Part 1.3: Baseline Error Analysis\n",
        "\n",
        "Analyze the baseline model's errors, confusion patterns, and identify artifact-related mistakes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hHVSEl6FXdee"
      },
      "outputs": [],
      "source": [
        "!python analyze/error_analysis.py\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkboHNmlXdee"
      },
      "source": [
        "### Part 1.4: Visualizations - Baseline Model\n",
        "\n",
        "Create visualizations to show error patterns and confusion matrices.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P3cpnJwIXdee"
      },
      "outputs": [],
      "source": [
        "!python analyze/visualize_baseline.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPuNSHXZXdee"
      },
      "source": [
        "## Part 2: Fix - Debiasing Implementation\n",
        "\n",
        "### Part 2.1: Train Debiased Model\n",
        "\n",
        "Train a debiased model using confidence-based reweighting.  \n",
        "Examples where the hypothesis-only model is confident (likely artifacts) are downweighted.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eo-18kBrXdef"
      },
      "outputs": [],
      "source": [
        "!python train/train_debiased.py\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKL0j8XJXdef",
        "outputId": "751ebfd2-f3a6-458e-ce59-3d2d5fa12f7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "Debiased Model Results\n",
            "================================================================================\n",
            "Accuracy: 0.8642 (86.42%)\n",
            "Eval Loss: 0.24399055540561676\n"
          ]
        }
      ],
      "source": [
        "# Check debiased results\n",
        "import json\n",
        "with open(os.path.join('outputs', 'evaluations', 'debiased_model', 'eval_metrics.json'), 'r') as f:\n",
        "    debiased_metrics = json.load(f)\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"Debiased Model Results\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"Accuracy: {debiased_metrics['eval_accuracy']:.4f} ({debiased_metrics['eval_accuracy']*100:.2f}%)\")\n",
        "print(f\"Eval Loss: {debiased_metrics.get('eval_loss', 'N/A')}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1DTPvezXdef",
        "outputId": "f8011c7d-eb0b-4a72-fedc-9dbd7a178f86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "Results Comparison - Baseline vs Debiased\n",
            "================================================================================\n",
            "\n",
            "Random Baseline:        0.3333 (33.33%)\n",
            "Hypothesis-Only:        0.6080 (60.80%) [Above random: +27.47%]\n",
            "Baseline (Full Model):  0.8654 (86.54%)\n",
            "Debiased:               0.8642 (86.42%) [Change: -0.12%]\n",
            "\n",
            "================================================================================\n",
            "Key Findings:\n",
            "================================================================================\n",
            "1. Hypothesis-Only model achieves 60.80%, proving strong artifacts exist!\n",
            "2. Debiasing maintains performance: 86.42% vs 86.54%\n",
            "3. Debiasing preserved performance\n",
            "\n",
            "================================================================================\n",
            "Per-Class Accuracy Comparison\n",
            "================================================================================\n",
            "Entailment     : Baseline=89.28%, Debiased=89.31%, Change=+0.03%\n",
            "Neutral        : Baseline=82.97%, Debiased=82.38%, Change=-0.59%\n",
            "Contradiction  : Baseline=87.28%, Debiased=87.46%, Change=+0.18%\n",
            "\n",
            "================================================================================\n",
            "Prediction Changes\n",
            "================================================================================\n",
            "Total predictions changed: 605 (6.1%)\n",
            "Baseline wrong -> Debiased correct (FIXES): 270\n",
            "Baseline correct -> Debiased wrong (BREAKS): 282\n",
            "Net improvement: -12\n",
            "\n",
            "Top 10 fixes saved to: /content/fp-dataset-artifacts/outputs/evaluations/fixes_examples.json\n"
          ]
        }
      ],
      "source": [
        "!python analyze/compare_results.py\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GiJjXSWIXdef"
      },
      "source": [
        "### Part 2.3: Visualizations - Comparison\n",
        "\n",
        "Create visualizations comparing baseline and debiased models.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92uQMFNgXdeg",
        "outputId": "e45f6270-479d-413f-b5d2-0aed58969506"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading metrics...\n",
            "Loading predictions...\n",
            "Creating comparison charts...\n",
            "Comparison chart saved to: /content/fp-dataset-artifacts/outputs/evaluations/baseline_vs_debiased_comparison.png\n",
            "Comparison visualizations completed!\n"
          ]
        }
      ],
      "source": [
        "!python analyze/visualize_comparison.py\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IeTmgwQ1Xdeg",
        "outputId": "312525bb-2204-48c3-8f0b-dbf16b415017"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "Examples Where Debiasing Fixed Baseline Errors\n",
            "================================================================================\n",
            "\n",
            "Fix Example 1:\n",
            "  Premise: A man selling donuts to a customer during a world exhibition event held in the city of Angeles\n",
            "  Hypothesis: A man selling donuts to a customer.\n",
            "  True Label: Entailment\n",
            "  Baseline Predicted: Neutral [WRONG]\n",
            "  Debiased Predicted: Entailment [CORRECT]\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Fix Example 2:\n",
            "  Premise: A senior is waiting at the window of a restaurant that serves sandwiches.\n",
            "  Hypothesis: A man is waiting in line for the bus.\n",
            "  True Label: Contradiction\n",
            "  Baseline Predicted: Neutral [WRONG]\n",
            "  Debiased Predicted: Contradiction [CORRECT]\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Fix Example 3:\n",
            "  Premise: Street performer with bowler hat and high boots performs outside.\n",
            "  Hypothesis: The man is performing a magic act.\n",
            "  True Label: Neutral\n",
            "  Baseline Predicted: Contradiction [WRONG]\n",
            "  Debiased Predicted: Neutral [CORRECT]\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Fix Example 4:\n",
            "  Premise: Number 916 is hoping that he is going to win the race.\n",
            "  Hypothesis: A person is betting that he will win  the race.\n",
            "  True Label: Neutral\n",
            "  Baseline Predicted: Entailment [WRONG]\n",
            "  Debiased Predicted: Neutral [CORRECT]\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Fix Example 5:\n",
            "  Premise: An older gentleman enjoys a scenic stroll through the countryside.\n",
            "  Hypothesis: An old man searches for a good place to die.\n",
            "  True Label: Neutral\n",
            "  Baseline Predicted: Contradiction [WRONG]\n",
            "  Debiased Predicted: Neutral [CORRECT]\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "!python analyze/show_fixes.py\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzrL5KsPiC4D"
      },
      "source": [
        "## Update"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FhiQXIfmiGB3",
        "outputId": "d554fab6-4c6f-4dc1-ac17-caa2e934e918"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "Changes not staged for commit:\n",
            "  (use \"git add <file>...\" to update what will be committed)\n",
            "  (use \"git restore <file>...\" to discard changes in working directory)\n",
            "\t\u001b[31mmodified:   outputs/evaluations/baseline_100k/eval_metrics.json\u001b[m\n",
            "\t\u001b[31mmodified:   outputs/evaluations/baseline_100k/eval_predictions.jsonl\u001b[m\n",
            "\n",
            "Untracked files:\n",
            "  (use \"git add <file>...\" to include in what will be committed)\n",
            "\t\u001b[31moutputs/evaluations/baseline_100k/checkpoint-1000/\u001b[m\n",
            "\t\u001b[31moutputs/evaluations/baseline_100k/checkpoint-1500/\u001b[m\n",
            "\t\u001b[31moutputs/evaluations/baseline_100k/checkpoint-2000/\u001b[m\n",
            "\t\u001b[31moutputs/evaluations/baseline_100k/checkpoint-2500/\u001b[m\n",
            "\t\u001b[31moutputs/evaluations/baseline_100k/checkpoint-3000/\u001b[m\n",
            "\t\u001b[31moutputs/evaluations/baseline_100k/checkpoint-3500/\u001b[m\n",
            "\t\u001b[31moutputs/evaluations/baseline_100k/checkpoint-4000/\u001b[m\n",
            "\t\u001b[31moutputs/evaluations/baseline_100k/checkpoint-4500/\u001b[m\n",
            "\t\u001b[31moutputs/evaluations/baseline_100k/checkpoint-500/\u001b[m\n",
            "\t\u001b[31moutputs/evaluations/baseline_100k/checkpoint-5000/\u001b[m\n",
            "\t\u001b[31moutputs/evaluations/baseline_100k/checkpoint-5500/\u001b[m\n",
            "\t\u001b[31moutputs/evaluations/baseline_100k/checkpoint-6000/\u001b[m\n",
            "\t\u001b[31moutputs/evaluations/baseline_100k/checkpoint-6500/\u001b[m\n",
            "\t\u001b[31moutputs/evaluations/baseline_100k/checkpoint-7000/\u001b[m\n",
            "\t\u001b[31moutputs/evaluations/baseline_100k/checkpoint-7500/\u001b[m\n",
            "\t\u001b[31moutputs/evaluations/baseline_100k/checkpoint-8000/\u001b[m\n",
            "\t\u001b[31moutputs/evaluations/baseline_100k/checkpoint-8500/\u001b[m\n",
            "\t\u001b[31moutputs/evaluations/baseline_100k/checkpoint-9000/\u001b[m\n",
            "\t\u001b[31moutputs/evaluations/baseline_100k/checkpoint-9375/\u001b[m\n",
            "\t\u001b[31moutputs/evaluations/baseline_100k/config.json\u001b[m\n",
            "\t\u001b[31moutputs/evaluations/baseline_100k/model.safetensors\u001b[m\n",
            "\t\u001b[31moutputs/evaluations/baseline_100k/runs/\u001b[m\n",
            "\t\u001b[31moutputs/evaluations/baseline_100k/special_tokens_map.json\u001b[m\n",
            "\t\u001b[31moutputs/evaluations/baseline_100k/tokenizer.json\u001b[m\n",
            "\t\u001b[31moutputs/evaluations/baseline_100k/tokenizer_config.json\u001b[m\n",
            "\t\u001b[31moutputs/evaluations/baseline_100k/training_args.bin\u001b[m\n",
            "\t\u001b[31moutputs/evaluations/baseline_100k/vocab.txt\u001b[m\n",
            "\t\u001b[31moutputs/evaluations/baseline_vs_debiased_comparison.png\u001b[m\n",
            "\t\u001b[31mwandb/\u001b[m\n",
            "\n",
            "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"
          ]
        }
      ],
      "source": [
        "!git config --global user.name \"DinaberryPi\"\n",
        "!git config --global user.email \"dinahenrykyy@gmail.com\"\n",
        "!git status"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m8zHnRvsiXwq"
      },
      "outputs": [],
      "source": [
        "!git add ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASkHPu5Lib5D",
        "outputId": "58e70348-85c7-433c-f904-da56ecfc6c7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "Changes to be committed:\n",
            "  (use \"git restore --staged <file>...\" to unstage)\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-1000/config.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-1000/model.safetensors\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-1000/optimizer.pt\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-1000/rng_state.pth\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-1000/scheduler.pt\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-1000/special_tokens_map.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-1000/tokenizer.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-1000/tokenizer_config.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-1000/trainer_state.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-1000/training_args.bin\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-1000/vocab.txt\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-1500/config.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-1500/model.safetensors\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-1500/optimizer.pt\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-1500/rng_state.pth\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-1500/scheduler.pt\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-1500/special_tokens_map.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-1500/tokenizer.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-1500/tokenizer_config.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-1500/trainer_state.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-1500/training_args.bin\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-1500/vocab.txt\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-2000/config.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-2000/model.safetensors\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-2000/optimizer.pt\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-2000/rng_state.pth\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-2000/scheduler.pt\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-2000/special_tokens_map.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-2000/tokenizer.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-2000/tokenizer_config.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-2000/trainer_state.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-2000/training_args.bin\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-2000/vocab.txt\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-2500/config.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-2500/model.safetensors\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-2500/optimizer.pt\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-2500/rng_state.pth\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-2500/scheduler.pt\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-2500/special_tokens_map.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-2500/tokenizer.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-2500/tokenizer_config.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-2500/trainer_state.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-2500/training_args.bin\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-2500/vocab.txt\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-3000/config.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-3000/model.safetensors\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-3000/optimizer.pt\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-3000/rng_state.pth\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-3000/scheduler.pt\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-3000/special_tokens_map.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-3000/tokenizer.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-3000/tokenizer_config.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-3000/trainer_state.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-3000/training_args.bin\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-3000/vocab.txt\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-3500/config.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-3500/model.safetensors\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-3500/optimizer.pt\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-3500/rng_state.pth\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-3500/scheduler.pt\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-3500/special_tokens_map.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-3500/tokenizer.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-3500/tokenizer_config.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-3500/trainer_state.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-3500/training_args.bin\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-3500/vocab.txt\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-4000/config.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-4000/model.safetensors\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-4000/optimizer.pt\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-4000/rng_state.pth\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-4000/scheduler.pt\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-4000/special_tokens_map.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-4000/tokenizer.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-4000/tokenizer_config.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-4000/trainer_state.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-4000/training_args.bin\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-4000/vocab.txt\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-4500/config.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-4500/model.safetensors\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-4500/optimizer.pt\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-4500/rng_state.pth\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-4500/scheduler.pt\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-4500/special_tokens_map.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-4500/tokenizer.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-4500/tokenizer_config.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-4500/trainer_state.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-4500/training_args.bin\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-4500/vocab.txt\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-500/config.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-500/model.safetensors\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-500/optimizer.pt\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-500/rng_state.pth\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-500/scheduler.pt\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-500/special_tokens_map.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-500/tokenizer.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-500/tokenizer_config.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-500/trainer_state.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-500/training_args.bin\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-500/vocab.txt\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-5000/config.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-5000/model.safetensors\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-5000/optimizer.pt\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-5000/rng_state.pth\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-5000/scheduler.pt\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-5000/special_tokens_map.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-5000/tokenizer.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-5000/tokenizer_config.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-5000/trainer_state.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-5000/training_args.bin\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-5000/vocab.txt\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-5500/config.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-5500/model.safetensors\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-5500/optimizer.pt\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-5500/rng_state.pth\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-5500/scheduler.pt\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-5500/special_tokens_map.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-5500/tokenizer.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-5500/tokenizer_config.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-5500/trainer_state.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-5500/training_args.bin\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-5500/vocab.txt\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-6000/config.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-6000/model.safetensors\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-6000/optimizer.pt\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-6000/rng_state.pth\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-6000/scheduler.pt\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-6000/special_tokens_map.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-6000/tokenizer.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-6000/tokenizer_config.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-6000/trainer_state.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-6000/training_args.bin\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-6000/vocab.txt\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-6500/config.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-6500/model.safetensors\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-6500/optimizer.pt\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-6500/rng_state.pth\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-6500/scheduler.pt\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-6500/special_tokens_map.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-6500/tokenizer.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-6500/tokenizer_config.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-6500/trainer_state.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-6500/training_args.bin\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-6500/vocab.txt\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-7000/config.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-7000/model.safetensors\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-7000/optimizer.pt\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-7000/rng_state.pth\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-7000/scheduler.pt\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-7000/special_tokens_map.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-7000/tokenizer.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-7000/tokenizer_config.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-7000/trainer_state.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-7000/training_args.bin\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-7000/vocab.txt\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-7500/config.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-7500/model.safetensors\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-7500/optimizer.pt\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-7500/rng_state.pth\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-7500/scheduler.pt\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-7500/special_tokens_map.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-7500/tokenizer.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-7500/tokenizer_config.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-7500/trainer_state.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-7500/training_args.bin\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-7500/vocab.txt\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-8000/config.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-8000/model.safetensors\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-8000/optimizer.pt\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-8000/rng_state.pth\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-8000/scheduler.pt\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-8000/special_tokens_map.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-8000/tokenizer.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-8000/tokenizer_config.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-8000/trainer_state.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-8000/training_args.bin\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-8000/vocab.txt\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-8500/config.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-8500/model.safetensors\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-8500/optimizer.pt\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-8500/rng_state.pth\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-8500/scheduler.pt\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-8500/special_tokens_map.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-8500/tokenizer.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-8500/tokenizer_config.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-8500/trainer_state.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-8500/training_args.bin\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-8500/vocab.txt\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-9000/config.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-9000/model.safetensors\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-9000/optimizer.pt\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-9000/rng_state.pth\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-9000/scheduler.pt\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-9000/special_tokens_map.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-9000/tokenizer.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-9000/tokenizer_config.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-9000/trainer_state.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-9000/training_args.bin\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-9000/vocab.txt\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-9375/config.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-9375/model.safetensors\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-9375/optimizer.pt\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-9375/rng_state.pth\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-9375/scheduler.pt\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-9375/special_tokens_map.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-9375/tokenizer.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-9375/tokenizer_config.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-9375/trainer_state.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-9375/training_args.bin\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/checkpoint-9375/vocab.txt\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/config.json\u001b[m\n",
            "\t\u001b[32mmodified:   outputs/evaluations/baseline_100k/eval_metrics.json\u001b[m\n",
            "\t\u001b[32mmodified:   outputs/evaluations/baseline_100k/eval_predictions.jsonl\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/model.safetensors\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/runs/Nov18_19-19-51_df5133b31964/events.out.tfevents.1763493635.df5133b31964.15703.0\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/runs/Nov18_19-19-51_df5133b31964/events.out.tfevents.1763495407.df5133b31964.15703.1\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/special_tokens_map.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/tokenizer.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/tokenizer_config.json\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/training_args.bin\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_100k/vocab.txt\u001b[m\n",
            "\t\u001b[32mnew file:   outputs/evaluations/baseline_vs_debiased_comparison.png\u001b[m\n",
            "\t\u001b[32mnew file:   wandb/debug-internal.log\u001b[m\n",
            "\t\u001b[32mnew file:   wandb/debug.log\u001b[m\n",
            "\t\u001b[32mnew file:   wandb/latest-run\u001b[m\n",
            "\t\u001b[32mnew file:   wandb/offline-run-20251118_193302-jrbbpz27/files/requirements.txt\u001b[m\n",
            "\t\u001b[32mnew file:   wandb/offline-run-20251118_193302-jrbbpz27/logs/debug-core.log\u001b[m\n",
            "\t\u001b[32mnew file:   wandb/offline-run-20251118_193302-jrbbpz27/logs/debug-internal.log\u001b[m\n",
            "\t\u001b[32mnew file:   wandb/offline-run-20251118_193302-jrbbpz27/logs/debug.log\u001b[m\n",
            "\t\u001b[32mnew file:   wandb/offline-run-20251118_193302-jrbbpz27/run-jrbbpz27.wandb\u001b[m\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!git status"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySKMz9lQiShn",
        "outputId": "1dc15bb1-6f13-4e66-cb1b-36a1bbff2194"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[main fac3e4b] update\n",
            " 229 files changed, 1238491 insertions(+), 9843 deletions(-)\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-1000/config.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-1000/model.safetensors\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-1000/optimizer.pt\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-1000/rng_state.pth\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-1000/scheduler.pt\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-1000/special_tokens_map.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-1000/tokenizer.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-1000/tokenizer_config.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-1000/trainer_state.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-1000/training_args.bin\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-1000/vocab.txt\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-1500/config.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-1500/model.safetensors\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-1500/optimizer.pt\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-1500/rng_state.pth\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-1500/scheduler.pt\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-1500/special_tokens_map.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-1500/tokenizer.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-1500/tokenizer_config.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-1500/trainer_state.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-1500/training_args.bin\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-1500/vocab.txt\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-2000/config.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-2000/model.safetensors\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-2000/optimizer.pt\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-2000/rng_state.pth\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-2000/scheduler.pt\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-2000/special_tokens_map.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-2000/tokenizer.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-2000/tokenizer_config.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-2000/trainer_state.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-2000/training_args.bin\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-2000/vocab.txt\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-2500/config.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-2500/model.safetensors\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-2500/optimizer.pt\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-2500/rng_state.pth\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-2500/scheduler.pt\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-2500/special_tokens_map.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-2500/tokenizer.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-2500/tokenizer_config.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-2500/trainer_state.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-2500/training_args.bin\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-2500/vocab.txt\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-3000/config.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-3000/model.safetensors\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-3000/optimizer.pt\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-3000/rng_state.pth\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-3000/scheduler.pt\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-3000/special_tokens_map.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-3000/tokenizer.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-3000/tokenizer_config.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-3000/trainer_state.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-3000/training_args.bin\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-3000/vocab.txt\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-3500/config.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-3500/model.safetensors\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-3500/optimizer.pt\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-3500/rng_state.pth\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-3500/scheduler.pt\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-3500/special_tokens_map.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-3500/tokenizer.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-3500/tokenizer_config.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-3500/trainer_state.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-3500/training_args.bin\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-3500/vocab.txt\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-4000/config.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-4000/model.safetensors\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-4000/optimizer.pt\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-4000/rng_state.pth\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-4000/scheduler.pt\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-4000/special_tokens_map.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-4000/tokenizer.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-4000/tokenizer_config.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-4000/trainer_state.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-4000/training_args.bin\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-4000/vocab.txt\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-4500/config.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-4500/model.safetensors\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-4500/optimizer.pt\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-4500/rng_state.pth\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-4500/scheduler.pt\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-4500/special_tokens_map.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-4500/tokenizer.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-4500/tokenizer_config.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-4500/trainer_state.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-4500/training_args.bin\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-4500/vocab.txt\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-500/config.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-500/model.safetensors\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-500/optimizer.pt\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-500/rng_state.pth\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-500/scheduler.pt\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-500/special_tokens_map.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-500/tokenizer.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-500/tokenizer_config.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-500/trainer_state.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-500/training_args.bin\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-500/vocab.txt\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-5000/config.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-5000/model.safetensors\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-5000/optimizer.pt\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-5000/rng_state.pth\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-5000/scheduler.pt\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-5000/special_tokens_map.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-5000/tokenizer.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-5000/tokenizer_config.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-5000/trainer_state.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-5000/training_args.bin\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-5000/vocab.txt\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-5500/config.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-5500/model.safetensors\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-5500/optimizer.pt\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-5500/rng_state.pth\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-5500/scheduler.pt\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-5500/special_tokens_map.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-5500/tokenizer.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-5500/tokenizer_config.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-5500/trainer_state.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-5500/training_args.bin\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-5500/vocab.txt\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-6000/config.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-6000/model.safetensors\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-6000/optimizer.pt\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-6000/rng_state.pth\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-6000/scheduler.pt\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-6000/special_tokens_map.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-6000/tokenizer.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-6000/tokenizer_config.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-6000/trainer_state.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-6000/training_args.bin\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-6000/vocab.txt\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-6500/config.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-6500/model.safetensors\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-6500/optimizer.pt\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-6500/rng_state.pth\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-6500/scheduler.pt\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-6500/special_tokens_map.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-6500/tokenizer.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-6500/tokenizer_config.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-6500/trainer_state.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-6500/training_args.bin\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-6500/vocab.txt\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-7000/config.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-7000/model.safetensors\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-7000/optimizer.pt\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-7000/rng_state.pth\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-7000/scheduler.pt\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-7000/special_tokens_map.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-7000/tokenizer.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-7000/tokenizer_config.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-7000/trainer_state.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-7000/training_args.bin\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-7000/vocab.txt\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-7500/config.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-7500/model.safetensors\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-7500/optimizer.pt\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-7500/rng_state.pth\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-7500/scheduler.pt\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-7500/special_tokens_map.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-7500/tokenizer.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-7500/tokenizer_config.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-7500/trainer_state.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-7500/training_args.bin\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-7500/vocab.txt\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-8000/config.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-8000/model.safetensors\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-8000/optimizer.pt\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-8000/rng_state.pth\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-8000/scheduler.pt\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-8000/special_tokens_map.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-8000/tokenizer.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-8000/tokenizer_config.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-8000/trainer_state.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-8000/training_args.bin\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-8000/vocab.txt\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-8500/config.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-8500/model.safetensors\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-8500/optimizer.pt\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-8500/rng_state.pth\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-8500/scheduler.pt\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-8500/special_tokens_map.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-8500/tokenizer.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-8500/tokenizer_config.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-8500/trainer_state.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-8500/training_args.bin\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-8500/vocab.txt\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-9000/config.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-9000/model.safetensors\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-9000/optimizer.pt\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-9000/rng_state.pth\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-9000/scheduler.pt\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-9000/special_tokens_map.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-9000/tokenizer.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-9000/tokenizer_config.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-9000/trainer_state.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-9000/training_args.bin\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-9000/vocab.txt\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-9375/config.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-9375/model.safetensors\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-9375/optimizer.pt\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-9375/rng_state.pth\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-9375/scheduler.pt\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-9375/special_tokens_map.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-9375/tokenizer.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-9375/tokenizer_config.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-9375/trainer_state.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-9375/training_args.bin\n",
            " create mode 100644 outputs/evaluations/baseline_100k/checkpoint-9375/vocab.txt\n",
            " create mode 100644 outputs/evaluations/baseline_100k/config.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/model.safetensors\n",
            " create mode 100644 outputs/evaluations/baseline_100k/runs/Nov18_19-19-51_df5133b31964/events.out.tfevents.1763493635.df5133b31964.15703.0\n",
            " create mode 100644 outputs/evaluations/baseline_100k/runs/Nov18_19-19-51_df5133b31964/events.out.tfevents.1763495407.df5133b31964.15703.1\n",
            " create mode 100644 outputs/evaluations/baseline_100k/special_tokens_map.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/tokenizer.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/tokenizer_config.json\n",
            " create mode 100644 outputs/evaluations/baseline_100k/training_args.bin\n",
            " create mode 100644 outputs/evaluations/baseline_100k/vocab.txt\n",
            " create mode 100644 outputs/evaluations/baseline_vs_debiased_comparison.png\n",
            " create mode 120000 wandb/debug-internal.log\n",
            " create mode 120000 wandb/debug.log\n",
            " create mode 120000 wandb/latest-run\n",
            " create mode 100644 wandb/offline-run-20251118_193302-jrbbpz27/files/requirements.txt\n",
            " create mode 120000 wandb/offline-run-20251118_193302-jrbbpz27/logs/debug-core.log\n",
            " create mode 100644 wandb/offline-run-20251118_193302-jrbbpz27/logs/debug-internal.log\n",
            " create mode 100644 wandb/offline-run-20251118_193302-jrbbpz27/logs/debug.log\n",
            " create mode 100644 wandb/offline-run-20251118_193302-jrbbpz27/run-jrbbpz27.wandb\n"
          ]
        }
      ],
      "source": [
        "!git commit -m \"update\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fpFRIpiiVYl",
        "outputId": "e5c5c3b9-82a7-4acf-d060-18fc712052b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enumerating objects: 150, done.\n",
            "Counting objects:   0% (1/150)\rCounting objects:   1% (2/150)\rCounting objects:   2% (3/150)\rCounting objects:   3% (5/150)\rCounting objects:   4% (6/150)\rCounting objects:   5% (8/150)\rCounting objects:   6% (9/150)\rCounting objects:   7% (11/150)\rCounting objects:   8% (12/150)\rCounting objects:   9% (14/150)\rCounting objects:  10% (15/150)\rCounting objects:  11% (17/150)\rCounting objects:  12% (18/150)\rCounting objects:  13% (20/150)\rCounting objects:  14% (21/150)\rCounting objects:  15% (23/150)\rCounting objects:  16% (24/150)\rCounting objects:  17% (26/150)\rCounting objects:  18% (27/150)\rCounting objects:  19% (29/150)\rCounting objects:  20% (30/150)\rCounting objects:  21% (32/150)\rCounting objects:  22% (33/150)\rCounting objects:  23% (35/150)\rCounting objects:  24% (36/150)\rCounting objects:  25% (38/150)\rCounting objects:  26% (39/150)\rCounting objects:  27% (41/150)\rCounting objects:  28% (42/150)\rCounting objects:  29% (44/150)\rCounting objects:  30% (45/150)\rCounting objects:  31% (47/150)\rCounting objects:  32% (48/150)\rCounting objects:  33% (50/150)\rCounting objects:  34% (51/150)\rCounting objects:  35% (53/150)\rCounting objects:  36% (54/150)\rCounting objects:  37% (56/150)\rCounting objects:  38% (57/150)\rCounting objects:  39% (59/150)\rCounting objects:  40% (60/150)\rCounting objects:  41% (62/150)\rCounting objects:  42% (63/150)\rCounting objects:  43% (65/150)\rCounting objects:  44% (66/150)\rCounting objects:  45% (68/150)\rCounting objects:  46% (69/150)\rCounting objects:  47% (71/150)\rCounting objects:  48% (72/150)\rCounting objects:  49% (74/150)\rCounting objects:  50% (75/150)\rCounting objects:  51% (77/150)\rCounting objects:  52% (78/150)\rCounting objects:  53% (80/150)\rCounting objects:  54% (81/150)\rCounting objects:  55% (83/150)\rCounting objects:  56% (84/150)\rCounting objects:  57% (86/150)\rCounting objects:  58% (87/150)\rCounting objects:  59% (89/150)\rCounting objects:  60% (90/150)\rCounting objects:  61% (92/150)\rCounting objects:  62% (93/150)\rCounting objects:  63% (95/150)\rCounting objects:  64% (96/150)\rCounting objects:  65% (98/150)\rCounting objects:  66% (99/150)\rCounting objects:  67% (101/150)\rCounting objects:  68% (102/150)\rCounting objects:  69% (104/150)\rCounting objects:  70% (105/150)\rCounting objects:  71% (107/150)\rCounting objects:  72% (108/150)\rCounting objects:  73% (110/150)\rCounting objects:  74% (111/150)\rCounting objects:  75% (113/150)\rCounting objects:  76% (114/150)\rCounting objects:  77% (116/150)\rCounting objects:  78% (117/150)\rCounting objects:  79% (119/150)\rCounting objects:  80% (120/150)\rCounting objects:  81% (122/150)\rCounting objects:  82% (123/150)\rCounting objects:  83% (125/150)\rCounting objects:  84% (126/150)\rCounting objects:  85% (128/150)\rCounting objects:  86% (129/150)\rCounting objects:  87% (131/150)\rCounting objects:  88% (132/150)\rCounting objects:  89% (134/150)\rCounting objects:  90% (135/150)\rCounting objects:  91% (137/150)\rCounting objects:  92% (138/150)\rCounting objects:  93% (140/150)\rCounting objects:  94% (141/150)\rCounting objects:  95% (143/150)\rCounting objects:  96% (144/150)\rCounting objects:  97% (146/150)\rCounting objects:  98% (147/150)\rCounting objects:  99% (149/150)\rCounting objects: 100% (150/150)\rCounting objects: 100% (150/150), done.\n",
            "Delta compression using up to 8 threads\n",
            "Compressing objects: 100% (141/141), done.\n",
            "error: RPC failed; HTTP 500 curl 22 The requested URL returned error: 500\n",
            "send-pack: unexpected disconnect while reading sideband packet\n",
            "Writing objects: 100% (144/144), 2.33 GiB | 10.26 MiB/s, done.\n",
            "Total 144 (delta 75), reused 0 (delta 0), pack-reused 0\n",
            "fatal: the remote end hung up unexpectedly\n",
            "Everything up-to-date\n"
          ]
        }
      ],
      "source": [
        "!git push origin main"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V5E1",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
